{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scRNA cell population change test\n",
    "\n",
    "The purpose of this method is to test whether cell populations sizes significantly different through $M$ covariats $X^{N\\times M}$. We assume the following data generating process of cell population counts $y_{ik}$ of $i\\in\\{1,..,N\\}$ samples and $k\\in\\{1,..,K\\}$ detected cell populations:\n",
    "\n",
    "\\begin{align}\n",
    "y_i &\\sim\\text{DirMult}(y_i^+,\\gamma_i)\\\\\n",
    "y_i^+ &= \\sum_{k=1}^K y_{i,k}\\\\\n",
    "\\log(\\gamma_{ij}) &\\sim \\alpha_j + x_i^T\\beta_j + V_{ij} \\\\\n",
    "\\alpha &\\sim \\text{MvN}(\\mu_0, \\sigma_{0}^2 I)\\\\\n",
    "\\beta_{j,k} &\\sim \\text{N}(0, \\nu_{\\beta,j}^2\\sigma_{\\beta,k}^2)\\\\\n",
    "V_i &\\sim \\text{MvN}(\\mathbf{0}, \\Sigma_i)\\\\\n",
    "\\sigma_0^2 &\\sim \\text{HalfCauchy}(0, 5)\\\\\n",
    "\\sigma_{\\beta,k}^2 &\\sim \\text{HalfCauchy}(0, 5)\\\\\n",
    "\\nu_{\\beta,j}^2 &\\sim \\text{HalfCauchy}(0, 1)\\\\\n",
    "\\Sigma_i &\\sim \\text{Inv-Wishart}(\\Psi_0, \\rho_0)\n",
    "\\end{align}\n",
    "\n",
    "$V_i$ characterize the unobserved characteristics that are associated with the mean count for cell type $k$ in subject $i$ and account for within-subject correlations.\n",
    "\n",
    "\n",
    "\n",
    "**Software requirements**\n",
    "- Python == 3.6\n",
    "- Tensorflow (nightly)\n",
    "- Tensorflow-probability (nightly, >= 0.6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import edward2 as ed\n",
    "import warnings\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "def make_simple_model(X,k,n_total):\n",
    "    \"\"\"\n",
    "    :param X: The feature matrix\n",
    "    :param y: cell counts\n",
    "    :param n_total: vector of total number of  \n",
    "    :returns: The tensorflow model\n",
    "    \"\"\"\n",
    "    n,m = X.shape\n",
    "    #hyperprios\n",
    "    nu = ed.HalfCauchy(0,1, sample_shape=m, name=\"nu\")\n",
    "    sigma_beta = ed.HalfCauchy(0, 5, sample_shape=k, name=\"sigma_beta\")\n",
    "    sigma_alpha = ed.HalfCauchy(0, 5, sample_shape=k, name=\"sigma_alpha\")\n",
    "\n",
    "        \n",
    "    #priors\n",
    "    alpha = ed.Normal(tf.zeros(k),\n",
    "                     scale=sigma_alpha, \n",
    "                     name=\"alpha\")\n",
    "    beta =  ed.Normal(tf.zeros([m,k]),\n",
    "                      scale=tf.tensordot(nu,sigma_beta, axes=0), \n",
    "                      name=\"beta\")\n",
    "\n",
    "    p = ed.Dirichlet(tf.exp(alpha + tf.matmul(X,beta)), name=\"p\")\n",
    "    outcomes = ed.Multinomial(total_count=n_total, \n",
    "                                probs=p, \n",
    "                                name=\"outcomes\")\n",
    "\n",
    "    return outcomes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10; m=3; k=5; m_r=1; k_r=1\n",
    "def generate_data(n=n, m=m, k=k, m_r=m_r, k_r=k_r,rho=0.4):\n",
    "\n",
    "    # Covaraits drawn from MvNormal(0, Cov) Cov_ij = p ^|i-j| , p=0.4\n",
    "    #Tibshirani for correlated covariats Tibshirani (1996) \n",
    "    #X_cov =np.array([[rho**np.abs(i-j) for j in range(k)] for i in range(k)])\n",
    "    X_cov = np.eye(m)\n",
    "    X = np.random.multivariate_normal(np.zeros(m), cov=X_cov, size=n).astype(np.float32)\n",
    " \n",
    "    k_r_idx = np.random.choice(range(k), size=m_r, replace=False)\n",
    "    m_r_idx = np.random.choice(range(m), size=k_r, replace=False)\n",
    "\n",
    "    # slope and intercepts\n",
    "    alphas = np.random.uniform(-2.3, 2.3, size=k)\n",
    "    betas = np.zeros((m,k))\n",
    "\n",
    "    for i in m_r_idx:\n",
    "        for j in k_r_idx:\n",
    "            #p = np.random.binomial(n=1, p= 0.5)\n",
    "            betas[i,j] = 2. \n",
    "    \n",
    "    xi = 0.01 #dispersion parameter\n",
    "    gamma = np.exp(alphas + np.matmul(X, betas))\n",
    "    #gamma_plus = gamma_raw.sum(axis=1)\n",
    "    #gamma = (gamma_raw/gamma_plus[:, None]) *((1-xi)/xi)\n",
    "    \n",
    "    y = np.zeros((n, k))\n",
    "    \n",
    "    # sample total number of reads:\n",
    "    n_total = np.random.randint(100, 500, size=n).astype(np.float32)\n",
    "    n_total =500\n",
    "    print(n_total)\n",
    "    for i in range(n):\n",
    "        pi = np.random.dirichlet(gamma[i,:])\n",
    "        #y[i,:] = np.random.multinomial(n_total[i], pi).astype(np.float32)\n",
    "        y[i,:] = np.random.multinomial(n_total, pi).astype(np.float32)\n",
    "    print()\n",
    "    return n_total,X,y,m_r_idx, k_r_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "\n",
      "y [[  7.   9.   0.   7. 477.]\n",
      " [ 20.   9.  29.   1. 441.]\n",
      " [ 88.   0.  61.   0. 351.]\n",
      " [ 37.  55. 234.   0. 174.]\n",
      " [116.  61.  77.   0. 246.]\n",
      " [  4.   0. 118.   4. 374.]\n",
      " [  0.   3. 478.   1.  18.]\n",
      " [ 72.  21.   0.   1. 406.]\n",
      " [ 41.   0.  19.  36. 404.]\n",
      " [ 69.   5.  75.   0. 351.]]\n"
     ]
    }
   ],
   "source": [
    "#sess = tf.Session()\n",
    "n_data, X_data, y_data, m_r_idx, k_r_ids = generate_data()\n",
    "#n_data = tf.to_float(n_data)\n",
    "#X_data = tf.to_float(X_data)\n",
    "#y_data = tf.to_float(y_data)\n",
    "print(\"y\",y_data)\n",
    "#with sess.as_default():\n",
    "model = make_simple_model(X_data,k,n_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_template = tf.make_template(\"model\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/benjamin/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_probability/python/distributions/multinomial.py:249: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1125\u001b[0m                                        \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m                                        sigcls=Signature)\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2193\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{!r} is not a callable object'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <ed.RandomVariable 'outcomes_1/' shape=(10, 5) dtype=float32> is not a callable object",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3084977e0321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtarget_log_prob_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_log_prob_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         num_leapfrog_steps=5))\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36msample_chain\u001b[0;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprevious_kernel_results\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m       \u001b[0mprevious_kernel_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     return tf.scan(\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/hmc.py\u001b[0m in \u001b[0;36mbootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    516\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbootstrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;34m\"\"\"Creates initial `previous_kernel_results` using a supplied `state`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m     \u001b[0mkernel_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size_update_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m       \u001b[0mstep_size_assign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size_update_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/metropolis_hastings.py\u001b[0m in \u001b[0;36mbootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmcmc_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bootstrap_results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         values=[init_state]):\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mpkr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_target_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/hmc.py\u001b[0m in \u001b[0;36mbootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0minit_target_log_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m           \u001b[0minit_grads_target_log_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m       ] = mcmc_util.maybe_call_fn_and_grads(self.target_log_prob_fn, init_state)\n\u001b[0m\u001b[1;32m    688\u001b[0m       return UncalibratedHamiltonianMonteCarloKernelResults(\n\u001b[1;32m    689\u001b[0m           \u001b[0mlog_acceptance_correction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_target_log_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/util.py\u001b[0m in \u001b[0;36mmaybe_call_fn_and_grads\u001b[0;34m(fn, fn_arg_list, result, grads, check_non_none_grads, name)\u001b[0m\n\u001b[1;32m    235\u001b[0m     fn_arg_list = (list(fn_arg_list) if is_list_like(fn_arg_list)\n\u001b[1;32m    236\u001b[0m                    else [fn_arg_list])\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_value_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_arg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     if not all(r.dtype.is_floating\n\u001b[1;32m    239\u001b[0m                for r in (result if is_list_like(result) else [result])):  # pylint: disable=superfluous-parens\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/util.py\u001b[0m in \u001b[0;36m_value_and_gradients\u001b[0;34m(fn, fn_arg_list, result, grads, name)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_arg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# Ensure we disable bijector cacheing in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3084977e0321>\u001b[0m in \u001b[0;36mtarget_log_prob_fn\u001b[0;34m(alpha, beta, nu, sigma_alpha, sigma_beta, p)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msigma_beta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma_beta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moutcomes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_probability/python/edward2/program_transformations.py\u001b[0m in \u001b[0;36mlog_joint_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mmodel_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_function_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0minterception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterceptor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_probability/python/edward2/program_transformations.py\u001b[0m in \u001b[0;36m_get_function_inputs\u001b[0;34m(f, src_kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# getargspec was deprecated in Python 3.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0margspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0margspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m# else. So to be fully backwards compatible, we catch all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# possible exceptions here, and reraise a TypeError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unsupported callable'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported callable"
     ]
    }
   ],
   "source": [
    "log_joint = ed.make_log_joint_fn(model)\n",
    "\n",
    "def target_log_prob_fn(alpha, beta, nu, sigma_alpha, sigma_beta, p):\n",
    "  \"\"\"Unnormalized target density as a function of states.\"\"\"\n",
    "  return log_joint(\n",
    "    X_data,\n",
    "    k,\n",
    "    n_data,\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    nu=nu,\n",
    "    sigma_alpha=sigma_alpha,\n",
    "    sigma_beta=sigma_beta,\n",
    "    p=p,\n",
    "    outcomes=y_data,\n",
    "  )\n",
    "\n",
    "\n",
    "# MCMC setup\n",
    "qnu = tf.zeros([m], name=\"qnu\")  # initial state\n",
    "qsigma_alpha = tf.zeros([k], name=\"qsigma_alpha\")  # initial state\n",
    "qsigma_beta = tf.zeros([k], name=\"qsigma_beta\")  # initial state\n",
    "qalpha = tf.ones([k], name=\"qalpha\")  # initial state\n",
    "qbeta = tf.ones([k,m], name=\"qbeta\")  # initial state\n",
    "qp = tf.ones([k,m], name=\"qp\")  # initial state\n",
    "\n",
    "\n",
    "states, kernels_results = tfp.mcmc.sample_chain(\n",
    "    num_results=5000,\n",
    "    num_burnin_steps=3000,\n",
    "    current_state=[qalpha, qbeta, qnu, qsigma_alpha, qsigma_beta,qp],\n",
    "    kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=target_log_prob_fn,\n",
    "        step_size=0.01,\n",
    "        num_leapfrog_steps=5))\n",
    "\n",
    "\n",
    "nu_, sigma_alpha_, sigma_beta_, alpha_, beta_, p_ = states\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  [\n",
    "      nu_,\n",
    "      sigma_alpha_,\n",
    "      sigma_beta_,\n",
    "      alpha_,\n",
    "      beta_,\n",
    "      p_\n",
    "  ] = sess.run([\n",
    "      nu_,\n",
    "      sigma_alpha_,\n",
    "      sigma_beta_,\n",
    "      alpha_,\n",
    "      beta_,\n",
    "      p_,\n",
    "      kernel_results.is_accepted,\n",
    "  ])\n",
    "\n",
    "\n",
    "num_accepted = np.sum(is_accepted_)\n",
    "print('Acceptance rate: {}'.format(num_accepted / num_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/miniconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "    from scipy.special import softmax\n",
    "    import numpy as np\n",
    "    import arviz as az\n",
    "\n",
    "    # Settings\n",
    "    D = 4  # number of dimensions\n",
    "    N = 100  # number of datapoints to generate\n",
    "    K = 5\n",
    "    n_total = [1000]*N\n",
    "\n",
    "    noise_std_true = 1.0\n",
    "\n",
    "    # Generate data\n",
    "    b_true = np.random.randn(K).astype(np.float32)  # bias (alpha)\n",
    "    w_true = np.random.randn(D, K).astype(np.float32)  # weights (beta)\n",
    "    x = np.random.randn(N, D).astype(np.float32)\n",
    "    noise = noise_std_true * np.random.randn(N, 1).astype(np.float32)\n",
    "    concentration = softmax(np.matmul(x, w_true) + b_true + noise)\n",
    "    y = np.zeros([N, K], dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        y[i, :] = np.random.multinomial(n_total[i], concentration[i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.stats import norm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import edward2 as ed\n",
    "tfd = tfp.distributions\n",
    "\n",
    "sns.set()\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "np.random.seed(111)\n",
    "tf.set_random_seed(111)\n",
    "\n",
    "def linear_regression(X,K,n_total):\n",
    "  N,D = X.shape      #number of dimensions\n",
    "  sigma_alpha = ed.HalfCauchy(tf.zeros([K]), tf.ones([K])*5, name=\"sigma_alpha\")\n",
    "  sigma_beta = ed.HalfCauchy(tf.zeros([K]), tf.ones([K])*5, name=\"simga_beta\")\n",
    "  nu = ed.HalfCauchy(tf.zeros([D]), tf.ones([D]), name=\"nu\")\n",
    "  coeffs = ed.Normal(        #normal prior on weights\n",
    "      loc=tf.zeros([D,K]),\n",
    "      scale=tf.ones([D,K]),\n",
    "      name=\"beta\")\n",
    "  bias = ed.Normal(          #normal prior on bias\n",
    "      loc=tf.zeros([K]), \n",
    "      scale=tf.ones([K]),\n",
    "      name=\"alpha\") \n",
    "  predictions = ed.DirichletMultinomial(   #normally-distributed noise\n",
    "      n_total,\n",
    "      concentration=tf.exp(tf.matmul(X, coeffs)+bias),\n",
    "      name=\"predictions\")\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_joint = ed.make_log_joint_fn(linear_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the log posterior probability\n",
    "def target_log_prob_fn(alpha, beta):\n",
    "  return log_joint(\n",
    "      X=x,\n",
    "      predictions=y,\n",
    "      K=K,\n",
    "      n_total=n_total,\n",
    "      beta=beta,\n",
    "      alpha=alpha\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMC Settings\n",
    "num_results = int(10e3) #number of hmc iterations\n",
    "n_burnin = int(5e3)     #number of burn-in steps\n",
    "step_size = 0.01\n",
    "num_leapfrog_steps = 10\n",
    "\n",
    "# Parameter sizes\n",
    "beta_size = [D,K]\n",
    "alpha_size = [K]\n",
    "\n",
    "# HMC transition kernel\n",
    "kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn=target_log_prob_fn,\n",
    "    step_size=step_size,\n",
    "    num_leapfrog_steps=num_leapfrog_steps)\n",
    "\n",
    "# Define the chain states\n",
    "states, kernel_results = tfp.mcmc.sample_chain(\n",
    "    num_results=num_results,\n",
    "    num_burnin_steps=n_burnin,\n",
    "    kernel=kernel,\n",
    "    current_state=[\n",
    "        tf.zeros(alpha_size, name='init_alpha'),\n",
    "        tf.zeros(beta_size, name='init_beta'),\n",
    "    ])\n",
    "alpha, beta = states\n",
    "\n",
    "with  tf.Session() as sess:\n",
    "  [\n",
    "      alpha_,\n",
    "      beta_,\n",
    "      is_accepted_,\n",
    "  ] = sess.run([\n",
    "      alpha,\n",
    "      beta,\n",
    "      kernel_results.is_accepted,\n",
    "  ])\n",
    "\n",
    "# Samples after burn-in\n",
    "alpha_samples = alpha_[n_burnin:,:]\n",
    "beta_samples = beta_[n_burnin:,:,:]\n",
    "accepted_samples = is_accepted_[n_burnin:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate: 98.5%\n"
     ]
    }
   ],
   "source": [
    "print('Acceptance rate: %0.1f%%' % (100*np.mean(accepted_samples)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.526279 , -0.7007637, -1.653993 , -2.4317858,  6.3784385],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_samples.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
